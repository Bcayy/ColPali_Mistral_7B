# ColPali: GÃ¶rsel & PDF TabanlÄ± Belge Anlama Sistemi

## Proje Ã–zeti

ColPali, kullanÄ±cÄ±larÄ±n PDF veya gÃ¶rsel dosyalar yÃ¼kleyerek bu belgelerden **doÄŸal dilde bilgi sorgulamasÄ±** yapmasÄ±na olanak tanÄ±yan bir belge anlama sistemidir. OCR ile metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼len belgeler embedding ile anlamsal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve LLM destekli yanÄ±tlar Ã¼retilir.

## AmaÃ§

* Belgelerin iÃ§eriÄŸinden anlamlÄ± bilgi Ã§Ä±karmak
* KullanÄ±cÄ± sorgularÄ±na **LLM tabanlÄ±, doÄŸru ve kÄ±sa yanÄ±tlar** Ã¼retmek
* **RAG (Retrieval-Augmented Generation)** ile kontekste dayalÄ± sorgu yanÄ±tlamak
* **Cevap highlightâ€™lama**, **sayfa filtresi** gibi Ã¶zellikleri desteklemek

---

## KullanÄ±lan Teknolojiler

| Katman       | Teknoloji                             | AmaÃ§                                        |
| ------------ | ------------------------------------- | ------------------------------------------- |
| GÃ¶rsel Okuma | `pytesseract`, `pdf2image`, `PIL`     | OCR ve gÃ¶rsel dÃ¶nÃ¼ÅŸÃ¼m                       |
| VektÃ¶rleme   | `ColPali Engine (ColQwen2)`           | Sayfa iÃ§eriÄŸini embedding olarak dÃ¶nÃ¼ÅŸtÃ¼rme |
| LLM          | `Mistral-7B-Instruct`, `transformers` | DoÄŸal dil yanÄ±t Ã¼retimi                     |
| LLM + RAG    | `LangChain`, `HuggingFacePipeline`    | Zincir tabanlÄ± sorgu + cevap                |
| ArayÃ¼z       | `Gradio Blocks`                       | EtkileÅŸimli uygulama                        |

---

## Sistem Mimarisi

1. KullanÄ±cÄ± PDF veya gÃ¶rsel yÃ¼kler
2. `pytesseract` ile OCR, `ColQwen2` ile embedding Ã§Ä±karÄ±lÄ±r
3. Langchain ile benzer sayfalar skora gÃ¶re sÄ±ralanÄ±r
4. `Mistral` LLM ile RAG mimarisi iÃ§inde cevap Ã¼retilir
5. ï¸ CevabÄ±n alÄ±ndÄ±ÄŸÄ± gÃ¶rsel bÃ¶lge highlight edilir

---

## ğŸ” ColPali NasÄ±l Ã‡alÄ±ÅŸÄ±r?

### 1. Girdi YÃ¼kleme

KullanÄ±cÄ± sistem arayÃ¼zÃ¼ Ã¼zerinden PDF veya resim dosyasÄ±nÄ± yÃ¼kler.

### 2. OCR (Optical Character Recognition)

Dosya sayfalarÄ± gÃ¶rÃ¼ntÃ¼lere Ã§evrilir ve `pytesseract` kullanÄ±larak gÃ¶rsellerdeki metinler tanÄ±nÄ±r. Bu adÄ±mda her kelimenin pozisyon bilgisi (bounding box) da alÄ±nÄ±r, bÃ¶ylece gÃ¶rselde highlight yapÄ±labilir.

### 3. Embedding Hesaplama

Her sayfanÄ±n OCR metni `ColPali Engine` ile **anlamsal vektÃ¶rlere** dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. Bu embeddingâ€™ler cacheâ€™e alÄ±nÄ±r, bÃ¶ylece aynÄ± dosya tekrar yÃ¼klenirse sÃ¼re kÄ±salÄ±r.

### 4. Sorgu GiriÅŸi ve Sorgu Embedâ€™i

KullanÄ±cÄ±nÄ±n girdiyi doÄŸal dildeki soru, encoder ile vektÃ¶rleÅŸtirilir. Bu embedding, sayfa vektÃ¶rleriyle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.

```python
images = convert_from_path(file.name, dpi=100)
dataloader = DataLoader(
    dataset=images,
    batch_size=1,
    collate_fn=lambda x: processor.process_images(x)
)
for batch in dataloader:
    batch = {k: v.to(model.device) for k, v in batch.items()}
    embeds = model(**batch)
```

### 5. Skor Hesaplama ve En Ä°yi SayfalarÄ±n SeÃ§imi

* Sorguya en yakÄ±n sayfalar `cosine similarity` ile bulunur. `Plaid index` ile en iyi 3 sayfa seÃ§ilir ve bu sayfalardaki metinler LLM'e verilir.

#### Cosine similarity
ColPaliâ€™de KullanÄ±mÄ±
* KullanÄ±cÄ±nÄ±n sorusu embed edilir.
* TÃ¼m sayfa embeddingâ€™leri ile karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.
* En yÃ¼ksek cosine skoruna sahip sayfalar, en anlamlÄ± sayfalardÄ±r.

#### Plaid index
ColPaliâ€™de KullanÄ±mÄ±:
* TÃ¼m sayfa embeddingâ€™leri Plaid Indexâ€™e yÃ¼klenir
* Sorgu vektÃ¶rÃ¼yle en benzer top-k sayfa hÄ±zlÄ±ca bulunur
* Bu sayfalar LLMâ€™e verilecek iÃ§erik olarak seÃ§ilir

![Skor](Skor.png)

### 6. LLM ile RAG (Retrieval-Augmented Generation)

SeÃ§ilen sayfa metinleri, prompt yapÄ±sÄ± ile birlikte **LLM** modeline verilir. Model, bu kontekste dayalÄ± Ã¶z ve anlamlÄ± bir cevap Ã¼retir.
* LangChain zinciri ÅŸÃ¶yle kurulu: PromptTemplate â†’ HF Pipeline â†’ Parser.
* Prompt: â€œContext: â€¦\n\nQuestion: â€¦\n\nAnswer:â€ formatÄ±nda.
* Mistral-7B modeli bu kontekste dayalÄ±, kÄ±sa ve Ã¶z bir cevap Ã¼retiyor.
* YanÄ±t sonrasÄ± CleanHFParser ile prompt kÄ±smÄ± temizleniyor.

```python
prompt_template = PromptTemplate.from_template(template)
qa_chain = prompt_template | llm_langchain | CleanHFParser()
```

### 7. Highlight Etme

Modelin cevabÄ±ndan anahtar ifade Ã§Ä±karÄ±lÄ±r ve OCR kutularÄ±yla karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r. En benzer kutu belirlenir ve ilgili bÃ¶lge gÃ¶rselde renklendirilir.
* Cevaptan gelen kÄ±sa metin OCR bloklarÄ±yla SequenceMatcher kullanÄ±larak eÅŸleÅŸtiriliyor.
* En iyi eÅŸleÅŸen kutu, ImageDraw ile sayfa Ã¼zerine ÅŸeffaf kÄ±rmÄ±zÄ± bir dikdÃ¶rtgenle iÅŸaretleniyor.

```python
def draw_highlight(image, box, color=(255, 0, 0, 80), width=2):
    overlay = Image.new("RGBA", image.size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(overlay)

    x0 = box["left"]
    y0 = box["top"]
    x1 = x0 + box["width"]
    y1 = y0 + box["height"]

    draw.rectangle([x0, y0, x1, y1], fill=color, outline=(255, 0, 0, 200), width=width)

    highlighted = Image.alpha_composite(image.convert("RGBA"), overlay)
    return highlighted.convert("RGB")
```

![Highlight](Highlight.png)

### 8. SonuÃ§larÄ±n GÃ¶rselleÅŸtirilmesi

* LLM yanÄ±tÄ±
* CevabÄ±n geldiÄŸi sayfanÄ±n highlight'Ä±
* Sayfa skorlarÄ± ve iÅŸlem sÃ¼releri
  kullanÄ±cÄ±ya sunulur.

![LLM](LLM.png)

---

## Ana Ã–zellikler

*  PDF/gÃ¶rsel iÃ§eriÄŸinden bilgi Ã§ekme
*  OCR + embedding + RAG destekli LLM cevaplama
*  Sayfa aralÄ±ÄŸÄ± filtresiyle sorgu kÄ±sÄ±tlama
*  CevabÄ±n geldiÄŸi gÃ¶rsel bÃ¶lgeyi Ä±ÅŸaretleme
*  KullanÄ±cÄ± dostu Gradio arayÃ¼z

---

## Sunum Ä°Ã§in Åablon: SÃ¼reler

| AÅŸama                  | SÃ¼re (saniye) | AÃ§Ä±klama                |
| ---------------------- |---------------| ----------------------- |
| PDF YÃ¼kleme & OCR      | `0.62`        | pdf2image + pytesseract |
| Embedding Ã‡Ä±karma      | `-`           | ColQwen2 modeli         |
| Sorgu Embed + Skorlama | `34.27`       | LangChain + Plaid       |
| LLM YanÄ±t              | `44.21`       | Mistral LLM Ã§Ä±ktÄ±sÄ±     |
| Toplam                 | `104.80`      | TÃ¼m sistem suresi       |

---

![Zaman](Zaman.png)
![LLM Suresi](LLM%20Suresi.png)

## Proje NotlarÄ±

* HF token ile Mistral 7B modeli Ã§ekilmektedir.
* Ã–nbellek ile tekrar embedding hesaplama azaltÄ±lÄ±r
* Kodlar GPU Ã¼yumlu Ã§alÄ±ÅŸacak ÅŸekilde dÃ¼zenlenmiÅŸtir

---

## Projeyi Neden SeÃ§tim?

* GerÃ§ek dÃ¼nya problemini Ã§Ã¶zÃ¼yor
* NLP + CV + RAG entegrasyonu sunuyor
* KullanÄ±cÄ± deneyimine odaklÄ±
* Teknik derinlik ve sunum kolaylÄ±ÄŸÄ± saÄŸlÄ±yor

---

## LLM KarÅŸÄ±laÅŸtÄ±rmasÄ±: Mistral-7B vs Phi-3-mini

| Ã–zellik                | **Mistral-7B-Instruct**                     | **Phi-3-mini-4k-instruct**                    |
|------------------------|---------------------------------------------|----------------------------------------------|
| Model Boyutu           | ~7B parametre                               | ~3.8B parametre                              |
| Bellek TÃ¼ketimi (fp16) | YÃ¼ksek (GPU RAM > 12 GB Ã¶nerilir)           | DÃ¼ÅŸÃ¼k (8 GB GPU Ã¼zerinde rahat Ã§alÄ±ÅŸÄ±r)      |
| Cevap Kalitesi         | Daha tutarlÄ±, baÄŸlama daha duyarlÄ±          | HÄ±zlÄ± yanÄ±t veriyor, ancak baÄŸlam Ã§Ã¶zÃ¼mlemesi sÄ±nÄ±rlÄ± |
| EÄŸitim Verisi          | GeniÅŸ & Instruct-tuned                      | Lightweight, metin odaklÄ±                    |
| Kontekst UzunluÄŸu      | 32k tokenâ€™a kadar destekler                 | 4k tokenâ€™a kadar                             |
| RAG UyumluluÄŸu         | Ã‡ok uygun â€“ kontekste gÃ¶re gÃ¼Ã§lÃ¼ genelleme  | SÄ±nÄ±rlÄ± baÄŸlam algÄ±sÄ±, kÄ±sa kontekstlerde iyi |
| HÄ±z                    | Orta (Ã¶zellikle CPUâ€™da)                   | YÃ¼ksek (hafifliÄŸi sayesinde hÄ±zlÄ± baÅŸlar)    |
| KullanÄ±m Durumu Ã–nerisi| KarmaÅŸÄ±k sorgular, detaylÄ± analizler        | Basit soru-cevap, dÃ¼ÅŸÃ¼k donanÄ±mlÄ± cihazlar   |

### Mistral
<img alt="Mistral" height="200" src="LLM.png" width="800"/>
<img alt="Phi-3" height="200" src="Phi-3.png" width="800"/>

### Neden Mistral-7Bâ€™i Ana Model Olarak SeÃ§tim?

- **YanÄ±t kalitesi** yÃ¼ksek ve uzun metinlerde **baÄŸlamÄ± iyi tutuyor**
- RAG yapÄ±sÄ±na uygun ÅŸekilde **top-3 sayfa Ã¼zerinden analiz** yapabiliyor
- ColPali mimarisi gibi Ã§ok bileÅŸenli sistemlerde **kararlÄ±lÄ±k ve esneklik saÄŸlÄ±yor**

### Phi-3-mini Ne Zaman KullanÄ±lÄ±r?

- HafifliÄŸi sayesinde **mobil/edge cihazlar** iÃ§in ideal
- **HÄ±zlÄ± prototipleme** veya dÃ¼ÅŸÃ¼k donanÄ±mlÄ± sistemlerde temel bilgi Ã§ekimi iÃ§in uygun
- KÄ±sa kontekstli, yÃ¶nlendirmesi aÃ§Ä±k sorularda etkili sonuÃ§lar Ã¼retir

---

## NasÄ±l GeliÅŸtirilebilir?

### Teknik GeliÅŸtirme

* Embed cache'leri daha etkili saklama

### UX OdaklÄ± GeliÅŸtirme

* Highlight alanÄ±na tÄ±klanÄ±labilirlik (interactive canvas)
* Cevaplanan soruyu PDF iÃ§inde gezebilme (PDF viewer)

---

## KarÅŸÄ±laÅŸÄ±lan Zorluklar ve Ã‡Ã¶zÃ¼m YollarÄ±

### 1.  LLM Ã‡Ä±ktÄ±sÄ±nda Promptâ€™un Tekrar DÃ¶nmesi
* Sorun: LLM yanÄ±tÄ± iÃ§inde prompt metni (Ã¶rn. â€œYou are a helpful assistantâ€¦â€) da tekrar ediyordu.
* Neden: transformers.pipeline() varsayÄ±lan olarak tÃ¼m textâ€™i dÃ¶ndÃ¼rÃ¼yor.
* Ã‡Ã¶zÃ¼m:
* return_full_text=False parametresi eklendi ve CleanHFParser sÄ±nÄ±fÄ± ile "Answer:" sonrasÄ± kÄ±smÄ± parse edecek yapÄ± kuruldu.

### 2. LangChain Zincirine Custom Output Parser Eklerken Hata
* Sorun: TypeError: Expected a Runnable... hatasÄ± alÄ±ndÄ±.
* Neden: CleanHFParser sÄ±nÄ±fÄ± Runnable olarak yazÄ±lmamÄ±ÅŸtÄ±.
* Ã‡Ã¶zÃ¼m:
* CleanHFParser(Runnable) sÄ±nÄ±fÄ± invoke fonksiyonuyla uyumlu hale getirildi.
* StrOutputParser() ile fallback olarak alternatif parser kullanÄ±labilir ÅŸekilde yapÄ±landÄ±.

### 3. LLM YanÄ±t SÃ¼resinin UzamasÄ±
* Sorun: YanÄ±t sÃ¼releri 50â€“170 saniye arasÄ±nda deÄŸiÅŸiyordu.
* Neden: Colab GPUâ€™da Mistral-7B Ã§alÄ±ÅŸÄ±rken bazen overload yaÅŸÄ±yor, Ã¶zellikle embedding + RAG eÅŸzamanlÄ± Ã§alÄ±ÅŸÄ±nca.
* Ã‡Ã¶zÃ¼m:
* Embedding Ã¶nceden cacheâ€™lendi (embedding_cache.pkl)
* LLMâ€™in max_new_tokens=512 sÄ±nÄ±rÄ± getirildi.
* Daha hafif alternatif olarak Phi-3-mini test edildi (daha hÄ±zlÄ± ama baÄŸlam zayÄ±f).

### 4. YanÄ±tÄ±n Highlight Edilememesi
* Sorun: BazÄ± cevaplar OCR bloklarÄ±nda birebir eÅŸleÅŸmediÄŸi iÃ§in highlight baÅŸarÄ±sÄ±z oluyordu.
* Ã‡Ã¶zÃ¼m:
* difflib.SequenceMatcher ile benzerlik skoru % eÅŸik deÄŸerine gÃ¶re optimize edildi.
* Gerekirse fallback olarak ilk sayfada gÃ¶sterim yapÄ±lmasÄ± eklendi.
* 
---

## HazÄ±rlayan

* Burak AKÃ‡AY
* [burakakcay44@gmail.com](mailto:burakakcay44@gmail.com)
* [LinkedIn](https://www.linkedin.com/in/burakakcay44/)

